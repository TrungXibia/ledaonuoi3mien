import streamlit as st
import pandas as pd
import logic
import data_fetcher
import concurrent.futures
from datetime import datetime, timedelta
import importlib
importlib.reload(data_fetcher)

# --- C·∫§U H√åNH ---
st.set_page_config(
    page_title="SI√äU G√Ä APP - PRO",
    page_icon="üêî",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- CSS FIX (T·ªëi ∆∞u cho b·∫£ng 20 c·ªôt) ---
st.markdown("""
<style>
    .block-container { padding-top: 1rem !important; padding-bottom: 1rem !important; }
    [data-testid="column"] { padding: 0 0.3rem !important; }
    
    /* Wrapper cho ph√©p cu·ªôn ngang */
    .table-wrapper { 
        overflow-x: auto; 
        margin: 10px 0; 
        border-radius: 6px; 
        box-shadow: 0 1px 4px rgba(0,0,0,0.1); 
        border: 1px solid #eee;
    }
    
    .tracking-table { 
        border-collapse: collapse; 
        width: 100%; 
        min-width: 800px; /* ƒê·∫£m b·∫£o b·∫£ng kh√¥ng b·ªã co qu√° nh·ªè */
        margin: 0 auto; 
        font-size: 10px; /* Font nh·ªè h∆°n x√≠u */
    }
    
    .tracking-table th { 
        padding: 4px 2px; 
        border: 1px solid #34495e; 
        background-color: #2c3e50; 
        color: white; 
        text-align: center; 
        position: sticky; 
        top: 0; 
        z-index: 10; 
        font-weight: 600; 
        min-width: 25px; /* Chi·ªÅu r·ªông t·ªëi thi·ªÉu cho c·ªôt N */
    }
    
    .tracking-table td { 
        padding: 2px 0px; 
        border: 1px solid #dee2e6; 
        text-align: center; 
        min-width: 25px;
    }
    
    .tracking-table td.moc-col { 
        font-weight: bold; 
        background-color: #f8f9fa; 
        color: #2c3e50; 
        min-width: 35px;
        font-size: 11px;
    }
    
    .tracking-table td.date-col {
        min-width: 60px;
        color: #666;
    }

    .cell-hit { background-color: #28a745 !important; color: white; font-weight: bold; font-size: 14px; }
    .cell-miss { background-color: #dc3545 !important; color: white; font-size: 12px; }
</style>
""", unsafe_allow_html=True)

# --- QU·∫¢N L√ù D·ªÆ LI·ªÜU ---
@st.cache_data(ttl=1800)
def get_master_data(num_days):
    with concurrent.futures.ThreadPoolExecutor() as executor:
        f_dt = executor.submit(data_fetcher.fetch_dien_toan, num_days)
        f_tt = executor.submit(data_fetcher.fetch_than_tai, num_days)
        # Fetch Full XSMB via API (includes G6, G7)
        f_mb = executor.submit(data_fetcher.fetch_xsmb_full, num_days)
        
        dt = f_dt.result()
        tt = f_tt.result()
        mb = f_mb.result()

    df_dt = pd.DataFrame(dt)
    df_tt = pd.DataFrame(tt)
    df_mb = pd.DataFrame(mb)
    
    # Prefix columns for MB to avoid collision if needed, but merge on date
    if not df_mb.empty:
        df_mb = df_mb.rename(columns={
            "g6_list": "mb_g6_list", 
            "g7_list": "mb_g7_list", 
            "db_2so": "mb_db_2so"
        })
        # Keep only necessary columns from MB for master table
        df_mb = df_mb[["date", "mb_db_2so", "mb_g6_list", "mb_g7_list"]]

    if not df_dt.empty:
        df = pd.merge(df_dt, df_tt, on="date", how="left")
        if not df_mb.empty:
            df = pd.merge(df, df_mb, on="date", how="left")
        return df
    return pd.DataFrame()

# --- SIDEBAR ---
with st.sidebar:
    st.title("üêî SI√äU G√Ä TOOL")
    st.caption("Version: 20 Days Matrix")
    days_fetch = st.number_input("S·ªë ng√†y t·∫£i:", 30, 365, 60, step=10)
    days_show = st.slider("Hi·ªÉn th·ªã d√≤ng:", 10, 100, 20)
    if st.button("üîÑ T·∫£i l·∫°i d·ªØ li·ªáu", type="primary"):
        st.cache_data.clear()
        st.rerun()

# --- LOAD DATA ---
try:
    with st.spinner("üöÄ ƒêang t·∫£i d·ªØ li·ªáu ƒëa lu·ªìng..."):
        df_full = get_master_data(days_fetch)
        if df_full.empty:
            st.error("Kh√¥ng c√≥ d·ªØ li·ªáu. Ki·ªÉm tra k·∫øt n·ªëi m·∫°ng.")
            st.stop()
except Exception as e:
    st.error(f"L·ªói: {e}")
    st.stop()

# === üéØ D√ÄN NU√îI (MATRIX) ===
st.title("üéØ D√ÄN NU√îI (MATRIX 20 NG√ÄY)")
st.divider()

# Row 1: Ngu·ªìn v√† Mi·ªÅn
c1, c2 = st.columns([1, 1])
src_mode = c1.selectbox("Ngu·ªìn (D√†n g·ªëc):", ["Th·∫ßn T√†i", "ƒêi·ªán To√°n"])
region = c2.selectbox("Mi·ªÅn:", ["Mi·ªÅn B·∫Øc", "Mi·ªÅn Nam", "Mi·ªÅn Trung"])

# Row 2: Logic Selection
selected_station = None
check_mode_desc = ""

if region == "Mi·ªÅn B·∫Øc":
    c3, c4, c5 = st.columns([1.5, 1.5, 1.5])
    # MB fixed comparison: G6 + G7
    c3.selectbox("So v·ªõi:", ["G6 + G7"], disabled=True)
    check_mode_desc = "G6 + G7"
    
    check_range = c4.slider("Khung nu√¥i (hi·ªÉn th·ªã N):", 1, 20, 20) # M·∫∑c ƒë·ªãnh max 20
    backtest_mode = c5.selectbox("Backtest:", ["Hi·ªán t·∫°i", "L√πi 1 ng√†y", "L√πi 2 ng√†y", "L√πi 3 ng√†y", "L√πi 4 ng√†y", "L√πi 5 ng√†y"])
    
else:
    c3, c4, c5, c6, c7 = st.columns([1, 1.2, 0.8, 1, 1])
    weekdays = ["T·∫•t c·∫£", "Ch·ªß Nh·∫≠t", "Th·ª© 2", "Th·ª© 3", "Th·ª© 4", "Th·ª© 5", "Th·ª© 6", "Th·ª© 7"]
    selected_day = c3.selectbox("Th·ª©:", weekdays)
    
    if selected_day == "T·∫•t c·∫£":
        selected_station = "T·∫•t c·∫£"
        c4.selectbox("ƒê√†i:", ["T·∫•t c·∫£"], disabled=True)
    else:
        stations = data_fetcher.get_stations_by_day(region, selected_day)
        station_options = ["T·∫•t c·∫£"] + stations
        selected_station = c4.selectbox("ƒê√†i:", station_options)
    
    # MN/MT fixed comparison: G6 + G7 + G8
    c5.selectbox("Gi·∫£i:", ["G6+G7+G8"], disabled=True)
    check_mode_desc = "G6 + G7 + G8"
    
    check_range = c6.slider("Khung (N):", 1, 20, 20)
    backtest_mode = c7.selectbox("Backtest:", ["Hi·ªán t·∫°i", "L√πi 1", "L√πi 2", "L√πi 3", "L√πi 4", "L√πi 5"])

backtest_offset = int(backtest_mode.split()[1]) if backtest_mode != "Hi·ªán t·∫°i" else 0

# === FETCH SPECIFIC REGION DATA ===
df_display = None
df_check_source = None

if region == "Mi·ªÅn B·∫Øc":
    df_display = df_full
    df_check_source = df_full
else:
    # Fetch MN/MT Data
    if selected_station == "T·∫•t c·∫£":
        all_stations = data_fetcher.get_all_stations_in_region(region)
        with st.spinner(f"üîÑ T·∫£i d·ªØ li·ªáu {region}..."):
            all_station_data = []
            with concurrent.futures.ThreadPoolExecutor() as executor:
                future_to_station = {executor.submit(data_fetcher.fetch_station_data, s, days_fetch): s for s in all_stations}
                for future in concurrent.futures.as_completed(future_to_station):
                    try:
                        data = future.result()
                        for item in data: item['station'] = future_to_station[future]
                        all_station_data.extend(data)
                    except: pass
            
            if not all_station_data: st.stop()
            
            # Group by date for consolidated checking
            df_temp = pd.DataFrame(all_station_data)
            grouped_data = []
            for date, group in df_temp.groupby('date'):
                day_values = []
                for _, row in group.iterrows():
                    day_values.extend(row.get('g6_list', []))
                    day_values.extend(row.get('g7_list', []))
                    day_values.extend(row.get('g8_list', []))
                
                if day_values:
                    grouped_data.append({'date': date, 'result_pool': list(set(day_values))})
            
            df_check_source = pd.DataFrame(grouped_data)
            df_check_source['date_obj'] = pd.to_datetime(df_check_source['date'], format='%d/%m/%Y')
            df_check_source = df_check_source.sort_values('date_obj', ascending=False).drop(columns=['date_obj'])
            
            if selected_day != "T·∫•t c·∫£":
                WEEKDAY_MAP = {"Th·ª© 2": 0, "Th·ª© 3": 1, "Th·ª© 4": 2, "Th·ª© 5": 3, "Th·ª© 6": 4, "Th·ª© 7": 5, "Ch·ªß Nh·∫≠t": 6}
                target = WEEKDAY_MAP.get(selected_day)
                df_display = df_check_source[df_check_source['date'].apply(lambda d: datetime.strptime(d, "%d/%m/%Y").weekday() == target)].copy()
            else:
                df_display = df_check_source.copy()
    else:
        with st.spinner(f"üîÑ T·∫£i {selected_station}..."):
            s_data = data_fetcher.fetch_station_data(selected_station, total_days=days_fetch)
            if not s_data: st.stop()
            
            p_data = []
            for item in s_data:
                pool = item.get('g6_list', []) + item.get('g7_list', []) + item.get('g8_list', [])
                p_data.append({'date': item['date'], 'result_pool': pool})
            
            df_display = pd.DataFrame(p_data)
            df_check_source = df_display

# === PREPARE ANALYSIS DATA ===
all_days_data = []
start_idx = backtest_offset
end_idx = min(backtest_offset + days_show, len(df_display))
df_full_lookup = df_full.set_index('date') if not df_full.empty else pd.DataFrame()

for i in range(start_idx, end_idx):
    row = df_display.iloc[i]
    date_val = row['date']
    
    row_src = None
    if region == "Mi·ªÅn B·∫Øc":
        row_src = row
    elif date_val in df_full_lookup.index:
        row_src = df_full_lookup.loc[date_val]
        if isinstance(row_src, pd.DataFrame): row_src = row_src.iloc[0]
    
    if row_src is None: continue

    src_str = ""
    if src_mode == "Th·∫ßn T√†i": 
        src_str = str(row_src.get('tt_number', ''))
    elif src_mode == "ƒêi·ªán To√°n": 
        val = row_src.get('dt_numbers', [])
        if isinstance(val, list): src_str = "".join(val)
        else: src_str = str(val) if pd.notna(val) else ""
    
    if not src_str or src_str == "nan": continue
    
    # === LOGIC D√ÄN NH·ªä H·ª¢P V√íNG ===
    combos = logic.tao_dan_nhi_hop_vong(src_str)
    
    if region == "Mi·ªÅn B·∫Øc":
        pool = row.get('mb_g6_list', []) + row.get('mb_g7_list', [])
    else:
        pool = row.get('result_pool', [])
        
    all_days_data.append({
        'date': date_val, 'source': src_str, 'combos': combos, 
        'index': i, 'result_pool': pool
    })

# === RENDER MATRIX ===
if all_days_data:
    st.markdown(f"### üìã B·∫£ng Theo D√µi ({check_mode_desc})")
    
    # === THAY ƒê·ªîI QUAN TR·ªåNG: MAX_COLS = 20 ===
    MAX_COLS = 20
    
    check_source_lookup = df_check_source.set_index('date') if df_check_source is not None else pd.DataFrame()
    
    table_html = "<div class='table-wrapper'><table class='tracking-table'><thead><tr>"
    table_html += "<th>Ng√†y</th><th>M·ªëc</th>"
    
    # Header N1 -> N20
    for k in range(1, MAX_COLS + 1): 
        table_html += f"<th>N{k}</th>"
    table_html += "</tr></thead><tbody>"
    
    for row_idx, day_data in enumerate(all_days_data):
        date, source, combos, i = day_data['date'], day_data['source'], day_data['combos'], day_data['index']
        table_html += f"<tr><td class='date-col'>{date}</td><td class='moc-col'>{source}</td>"
        
        # S·ªë ng√†y ƒë√£ qua k·ªÉ t·ª´ ng√†y t·∫°o c·∫ßu (ƒë·ªÉ t√¥ m√†u tam gi√°c)
        days_passed = row_idx + 1
        
        for k in range(1, MAX_COLS + 1):
            # Ch·ªâ hi·ªÉn th·ªã √¥ n·∫øu n·∫±m trong v√πng tam gi√°c
            if k > days_passed:
                table_html += "<td style='background-color:#f8f9fa'></td>"
                continue
                
            # Get Check Pool
            check_pool = []
            if selected_station == "T·∫•t c·∫£" and region != "Mi·ªÅn B·∫Øc":
                try:
                    c_date = (datetime.strptime(date, "%d/%m/%Y") + timedelta(days=k)).strftime("%d/%m/%Y")
                    if c_date in check_source_lookup.index:
                        r = check_source_lookup.loc[c_date]
                        if isinstance(r, pd.DataFrame): r = r.iloc[0]
                        check_pool = r.get('result_pool', [])
                except: pass
            else:
                idx = i - k
                if idx >= 0:
                    r = df_display.iloc[idx]
                    if region == "Mi·ªÅn B·∫Øc":
                        check_pool = r.get('mb_g6_list', []) + r.get('mb_g7_list', [])
                    else:
                        check_pool = r.get('result_pool', [])

            # Check Hit
            is_hit = False
            for num in combos:
                if num in check_pool:
                    is_hit = True
                    break
            
            if is_hit: table_html += "<td class='cell-hit'>‚úì</td>"
            elif check_pool: table_html += "<td class='cell-miss'>‚àí</td>"
            else: table_html += "<td>‚àí</td>"
            
        table_html += "</tr>"
    table_html += "</tbody></table></div>"
    st.markdown(table_html, unsafe_allow_html=True)
    
    # === STATISTICS ===
    st.markdown("---")
    st.caption("Ghi ch√∫: B·∫£ng hi·ªÉn th·ªã t·ªëi ƒëa 20 ng√†y nu√¥i.")
    
    pending = []
    for row_idx, day_data in enumerate(all_days_data):
        combos = day_data['combos']
        has_hit = False
        # Ch·ªâ check t·ªëi ƒëa ƒë·∫øn MAX_COLS (20 ng√†y) ho·∫∑c s·ªë ng√†y th·ª±c t·∫ø ƒë√£ qua
        num_checks = min(row_idx + 1, MAX_COLS)
        
        for k in range(1, num_checks + 1):
            check_pool = []
            if selected_station == "T·∫•t c·∫£" and region != "Mi·ªÅn B·∫Øc":
                try:
                    c_date = (datetime.strptime(day_data['date'], "%d/%m/%Y") + timedelta(days=k)).strftime("%d/%m/%Y")
                    if c_date in check_source_lookup.index:
                        r = check_source_lookup.loc[c_date]
                        if isinstance(r, pd.DataFrame): r = r.iloc[0]
                        check_pool = r.get('result_pool', [])
                except: pass
            else:
                idx = day_data['index'] - k
                if idx >= 0:
                    r = df_display.iloc[idx]
                    if region == "Mi·ªÅn B·∫Øc":
                        check_pool = r.get('mb_g6_list', []) + r.get('mb_g7_list', [])
                    else:
                        check_pool = r.get('result_pool', [])
            
            if any(c in check_pool for c in combos):
                has_hit = True
                break
        
        if not has_hit:
            pending.append({
                "Ng√†y": day_data['date'],
                "D√†n s·ªë": ", ".join(combos),
                "S·ªë l∆∞·ª£ng": len(combos),
                "ƒê√£ nu√¥i": f"{num_checks} ng√†y"
            })

    if pending:
        st.subheader(f"üî• C√°c D√†n Ch∆∞a Ra (Trong {MAX_COLS} ng√†y)")
        st.dataframe(pd.DataFrame(pending), use_container_width=True)
    else:
        st.success(f"Tuy·ªát v·ªùi! T·∫•t c·∫£ c√°c d√†n ƒë√£ n·ªï trong v√≤ng {MAX_COLS} ng√†y.")
